{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('input your path to dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "def ie_preprocess(document):\n",
    "#     document = ' '.join([i for i in document.split() if i not in stop])\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def extract_names(document):\n",
    "    names = []\n",
    "    sentences = ie_preprocess(document)\n",
    "    for tagged_sentence in sentences:\n",
    "        for chunk in nltk.ne_chunk(tagged_sentence, binary=False):\n",
    "            if type(chunk) == nltk.tree.Tree:\n",
    "                if chunk.label() == 'PERSON':\n",
    "                    names.append(' '.join([c[0] for c in chunk ]))\n",
    "                    \n",
    "    names_set=[]\n",
    "    for i in names:\n",
    "        if i in names_set or len(i.split()) < 2 :\n",
    "            pass\n",
    "        else:\n",
    "            names_set.append(i)\n",
    "    return list(map(str, names_set))\n",
    "\n",
    "\n",
    "def extract_first_name(document):\n",
    "    names= re.findall(\"Dear\\s\\w+|Mr.\\s\\w+\", document)\n",
    "    if len(names)> 0:\n",
    "        for name in names:\n",
    "            return str(name.split()[1])\n",
    "    else:\n",
    "        return 'unavailable'\n",
    "\n",
    "    \n",
    "def extract_full_name(document):\n",
    "    \n",
    "    full_name=[]\n",
    "   \n",
    "    first_name= extract_first_name(document)\n",
    "    if first_name != 'unavailable':\n",
    "        name_list= extract_names(document)\n",
    "        for names in name_list:\n",
    "            match= re.findall(first_name, names)\n",
    "            if len(match) >0 :\n",
    "                full_name.append(names)\n",
    "    else:\n",
    "        name_list= extract_names(document)\n",
    "        for names in name_list:\n",
    "            match= re.findall(\"Corporation|Inc\", names)\n",
    "            if len(match) >0:\n",
    "                pass\n",
    "            else:\n",
    "                full_name.append(names)\n",
    "    \n",
    "    return full_name\n",
    "\n",
    "def extract_organization(document):\n",
    "    document= \" \". join([i.lower() for i in document.split()])\n",
    "    splitted=[]\n",
    "    for i in document.split():\n",
    "        i= i.replace(\"â€™\", \"\")\n",
    "        splitted.append(i)\n",
    "    document= \" \".join(splitted)\n",
    "    try:\n",
    "        match= re.findall('[a-z]+\\s[a-z]+\\scorporation|[a-z]+\\sCorporation|[a-z]+\\s[a-z]+[,]*\\s*inc[.]|[a-z]+[,]*\\s*inc[.]', document)\n",
    "        return match[0]\n",
    "    except:\n",
    "        return 'unavailable'\n",
    "    \n",
    "def extract_base_salary(string):\n",
    "    try:\n",
    "        money = re.findall(\"(\\$\\d*[,]*\\d*[,]*\\d{3})\", string)\n",
    "        base_salary=[]\n",
    "        for salary in money:\n",
    "            salary= salary.replace('$', \"\")\n",
    "            salary= salary.replace(',', \"\")\n",
    "            salary= int(salary)\n",
    "            base_salary.append(salary)\n",
    "        \n",
    "        return '$' + str(sorted(base_salary)[::-1][0])\n",
    "    except:\n",
    "        money = re.findall(\"(\\d*[,]*\\d+[,]\\d{3})\", string)\n",
    "        base_salary=[]\n",
    "        for salary in money:\n",
    "            salary= salary.replace('$', \"\")\n",
    "            salary= salary.replace(',', \"\")\n",
    "            salary= int(salary)\n",
    "            base_salary.append(salary)\n",
    "        if len(base_salary)>0:\n",
    "            return base_salary[0]\n",
    "        else:\n",
    "            return 'unavailable or in Text Format'\n",
    "\n",
    "    \n",
    "def extract_agreement_date(document):\n",
    "    document= \" \". join([i.lower() for i in document.split()])\n",
    "    try:\n",
    "        dates= re.findall(\"(\\w+\\s[0-9]+[,]\\s[0-9]+)\", document)\n",
    "\n",
    "        if len(dates) > 0:\n",
    "            dates_set=[]\n",
    "            for date in dates:\n",
    "                if date in dates_set:\n",
    "                    pass\n",
    "                else:\n",
    "                    dates_set.append(date)    \n",
    "            return dates_set[0]\n",
    "    except:\n",
    "        return 'unavailable'\n",
    "\n",
    "\n",
    "def extract_role(document):\n",
    "    document= \" \". join([i.lower() for i in document.split()])\n",
    "    try:\n",
    "        roles= re.findall(\"chief financial Officer|chief executive officer|chief operations officer|senior vice president|chief operating Officer|manager| strategic marketing & development advisor| chief procurement officer| vp | vice president| business development\", document)\n",
    "        \n",
    "        roles_set=[]\n",
    "        for role in roles:\n",
    "            if role in roles_set:\n",
    "                pass\n",
    "            else:\n",
    "                roles_set.append(role)\n",
    "        return roles_set[0:2]\n",
    "    \n",
    "    except:\n",
    "        return 'unavailable'\n",
    "\n",
    "def file_segregation():\n",
    "    all_letters= os.listdir()\n",
    "\n",
    "    employment_letter=[]\n",
    "    amendment_letter=[]\n",
    "\n",
    "    for letters in all_letters:\n",
    "        match= re.findall(\"AMENDMENT|AMENDED|AMEND.|AMENDED|ADDENDUM|AMENDMEDNT|AM\", letters)\n",
    "        if len(match)>0:\n",
    "            amendment_letter.append(letters)\n",
    "        else:\n",
    "            employment_letter.append(letters)\n",
    "            \n",
    "    return employment_letter\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# exporting everything to CSV format\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    column= ['agreement', 'employee_name', 'employer', 'base_salary', 'agreement_date', 'role']\n",
    "    \n",
    "    employment_letter= file_segregation()\n",
    "    \n",
    "    employment_agreement= pd.DataFrame(columns= column, index=[i for i in range(len(employment_letter))])\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for letters in employment_letter:\n",
    "        text_file = open(letters, \"r\", encoding=\"utf8\")\n",
    "        document = text_file.read()\n",
    "\n",
    "\n",
    "        employment_agreement['agreement'].loc[i]= letters\n",
    "        employment_agreement['employee_name'].loc[i]= extract_full_name(document)\n",
    "        employment_agreement['employer'].loc[i]= extract_organization(document)\n",
    "        employment_agreement['base_salary'].loc[i]= extract_base_salary(document)\n",
    "        employment_agreement['agreement_date'].loc[i]= extract_agreement_date(document)\n",
    "        employment_agreement['role'].loc[i]= extract_role(document)\n",
    "\n",
    "        i= i+1\n",
    "    \n",
    "    employment_agreement.to_csv(\"Features_employment_agreement.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
